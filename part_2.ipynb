{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_reviews'\n",
    "\n",
    "# Load BERT embeddings\n",
    "x_train_BERT = np.load(os.path.join(data_dir, 'x_train_BERT_embeddings.npy'))\n",
    "x_test_BERT = np.load(os.path.join(data_dir, 'x_test_BERT_embeddings.npy'))\n",
    "\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "x_test_df = pd.read_csv(os.path.join(data_dir, 'x_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentiment labels and review sources\n",
    "train_labels = y_train_df['is_positive_sentiment'].values\n",
    "review_sources = x_train_df['website_name'].values  # Assuming 'website_name' is the column with review type\n",
    "\n",
    "# Split data based on the review source (e.g., 'amazon', 'imdb', 'yelp')\n",
    "train_amazon_indices = np.where(review_sources == 'amazon')[0]\n",
    "train_imdb_indices = np.where(review_sources == 'imdb')[0]\n",
    "train_yelp_indices = np.where(review_sources == 'yelp')[0]\n",
    "\n",
    "# Get corresponding embeddings and labels for each type\n",
    "x_train_amazon = x_train_BERT[train_amazon_indices]\n",
    "y_train_amazon = train_labels[train_amazon_indices]\n",
    "\n",
    "x_train_imdb = x_train_BERT[train_imdb_indices]\n",
    "y_train_imdb = train_labels[train_imdb_indices]\n",
    "\n",
    "x_train_yelp = x_train_BERT[train_yelp_indices]\n",
    "y_train_yelp = train_labels[train_yelp_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2']         # Penalty type\n",
    "}\n",
    "\n",
    "# Logistic Regression model setup\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Define AUROC as the evaluation metric\n",
    "scorer = make_scorer(roc_auc_score, greater_is_better=True)\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run grid search for a specific dataset\n",
    "def run_grid_search(x_train, y_train):\n",
    "    grid_search = GridSearchCV(log_reg, param_grid=param_grid, scoring=scorer, cv=skf, n_jobs=-1)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "# Run grid search for each review type\n",
    "grid_amazon = run_grid_search(x_train_amazon, y_train_amazon)\n",
    "grid_imdb = run_grid_search(x_train_imdb, y_train_imdb)\n",
    "grid_yelp = run_grid_search(x_train_yelp, y_train_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already loaded x_test_BERT and x_test_df as in your previous code\n",
    "# Extract website names from the test set\n",
    "test_sources = x_test_df['website_name'].values\n",
    "\n",
    "# Split the test data based on the review source\n",
    "test_amazon_indices = np.where(test_sources == 'amazon')[0]\n",
    "test_imdb_indices = np.where(test_sources == 'imdb')[0]\n",
    "test_yelp_indices = np.where(test_sources == 'yelp')[0]\n",
    "\n",
    "# Get corresponding embeddings for each type\n",
    "x_test_amazon = x_test_BERT[test_amazon_indices]\n",
    "x_test_imdb = x_test_BERT[test_imdb_indices]\n",
    "x_test_yelp = x_test_BERT[test_yelp_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best models to make predictions\n",
    "predictions_amazon = grid_amazon.best_estimator_.predict(x_test_amazon)\n",
    "predictions_imdb = grid_imdb.best_estimator_.predict(x_test_imdb)\n",
    "predictions_yelp = grid_yelp.best_estimator_.predict(x_test_yelp)\n",
    "\n",
    "# If you need probabilities instead of class predictions:\n",
    "probabilities_amazon = grid_amazon.best_estimator_.predict_proba(x_test_amazon)[:, 1]\n",
    "probabilities_imdb = grid_imdb.best_estimator_.predict_proba(x_test_imdb)[:, 1]\n",
    "probabilities_yelp = grid_yelp.best_estimator_.predict_proba(x_test_yelp)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.concatenate([probabilities_amazon, probabilities_imdb, probabilities_yelp])\n",
    "np.savetxt('yproba1_test(part2).txt', all_predictions, delimiter='\\n', fmt='%.6f')  # All predictions in one file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
